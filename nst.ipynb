{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-25-ff3fdeacb9ac>, line 8)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;36m  File \u001B[0;32m\"<ipython-input-25-ff3fdeacb9ac>\"\u001B[0;36m, line \u001B[0;32m8\u001B[0m\n\u001B[0;31m    from /Users/pranavtomar/PycharmProjects/ImageFilterandArtwork/nst_utils.ipynb import *\u001B[0m\n\u001B[0m         ^\u001B[0m\n\u001B[0;31mSyntaxError\u001B[0m\u001B[0;31m:\u001B[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import scipy.io\n",
    "import scipy.misc\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "from tensorflow.python.framework import ops\n",
    "from prorp.ipynb import get_\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "#%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "def compute_content_cost(a_C, a_G):\n",
    "\n",
    "    # Retrieve dimensions from a_G (≈1 line)\n",
    "    m, n_H, n_W, n_C = a_G.get_shape().as_list()\n",
    "\n",
    "    # Reshape a_C and a_G (≈2 lines)\n",
    "    a_C_unrolled = tf.transpose(tf.reshape(a_C, shape=[n_H*n_W*n_C]))\n",
    "    a_G_unrolled = tf.transpose(tf.reshape(a_G, shape=[n_H*n_W*n_C]))\n",
    "\n",
    "    # compute the cost with tensorflow (≈1 line)\n",
    "    J_content = (1/(4*n_H*n_W*n_C))*tf.reduce_sum(tf.square(tf.subtract(a_C_unrolled, a_G_unrolled)))\n",
    "\n",
    "    return J_content\n",
    "\n",
    "def gram_matrix(A):\n",
    "\n",
    "    GA = tf.matmul(A,tf.transpose(A))\n",
    "\n",
    "    return GA\n",
    "\n",
    "def compute_layer_style_cost(a_S, a_G):\n",
    "\n",
    "    # Retrieve dimensions from a_G (≈1 line)\n",
    "    m, n_H, n_W, n_C = a_G.get_shape().as_list()\n",
    "\n",
    "    # Reshape the images to have them of shape (n_C, n_H*n_W) (≈2 lines)\n",
    "    a_S = tf.transpose(tf.reshape(a_S,shape=[n_H*n_W, n_C]))\n",
    "    a_G = tf.transpose(tf.reshape(a_G,shape=[n_H*n_W, n_C]))\n",
    "\n",
    "    # Computing gram_matrices for both images S and G (≈2 lines)\n",
    "    GS = gram_matrix(a_S)\n",
    "    GG = gram_matrix(a_G)\n",
    "\n",
    "    # Computing the loss (≈1 line)\n",
    "    J_style_layer = (1/(4*(n_C**2)*(n_H*n_W)**2))*tf.reduce_sum(tf.square(tf.subtract(GS, GG)))\n",
    "\n",
    "    return J_style_layer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "STYLE_LAYERS = [\n",
    "    ('conv1_1', 0.2),\n",
    "    ('conv2_1', 0.2),\n",
    "    ('conv3_1', 0.2),\n",
    "    ('conv4_1', 0.2),\n",
    "    ('conv5_1', 0.2)]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "def compute_style_cost(model, STYLE_LAYERS):\n",
    "\n",
    "    # initialize the overall style cost\n",
    "    J_style = 0\n",
    "\n",
    "    for layer_name, coeff in STYLE_LAYERS:\n",
    "\n",
    "        # Select the output tensor of the currently selected layer\n",
    "        out = model[layer_name]\n",
    "\n",
    "        # Set a_S to be the hidden layer activation from the layer we have selected, by running the session on out\n",
    "        a_S = sess.run(out)\n",
    "\n",
    "        # Set a_G to be the hidden layer activation from same layer. Here, a_G references model[layer_name]\n",
    "        # and isn't evaluated yet. Later in the code, we'll assign the image G as the model input, so that\n",
    "        # when we run the session, this will be the activations drawn from the appropriate layer, with G as input.\n",
    "        a_G = out\n",
    "\n",
    "        # Compute style_cost for the current layer\n",
    "        J_style_layer = compute_layer_style_cost(a_S, a_G)\n",
    "\n",
    "        # Add coeff * J_style_layer of this layer to overall style cost\n",
    "        J_style += coeff * J_style_layer\n",
    "\n",
    "    return J_style"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "def total_cost(J_content, J_style, alpha = 10, beta = 40):\n",
    "\n",
    "    J = alpha*J_content + beta*J_style\n",
    "\n",
    "    return J"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'InteractiveSession'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-23-415f981963e2>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;31m# Start interactive session\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 5\u001B[0;31m \u001B[0msess\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mInteractiveSession\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      6\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[0mcontent_image\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mscipy\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmisc\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mimread\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"images/city.jpg\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mAttributeError\u001B[0m: module 'tensorflow' has no attribute 'InteractiveSession'"
     ]
    }
   ],
   "source": [
    "# Reset the graph\n",
    "ops.reset_default_graph()\n",
    "\n",
    "# Start interactive session\n",
    "sess = ops.InteractiveSession()\n",
    "\n",
    "content_image = scipy.misc.imread(\"images/city.jpg\")\n",
    "content_image = reshape_and_normalize_image(content_image)\n",
    "\n",
    "style_image = scipy.misc.imread(\"images/monet.jpg\")\n",
    "style_image = reshape_and_normalize_image(style_image)\n",
    "\n",
    "generated_image = generate_noise_image(content_image)\n",
    "imshow(generated_image[0])\n",
    "\n",
    "model = load_vgg_model(\"pretrained-model/imagenet-vgg-verydeep-19.mat\")\n",
    "\n",
    "# Assign the content image to be the input of the VGG model.\n",
    "sess.run(model['input'].assign(content_image))\n",
    "\n",
    "# Select the output tensor of layer conv4_2\n",
    "out = model['conv4_2']\n",
    "\n",
    "# Set a_C to be the hidden layer activation from the layer we have selected\n",
    "a_C = sess.run(out)\n",
    "\n",
    "# Set a_G to be the hidden layer activation from same layer. Here, a_G references model['conv4_2']\n",
    "# and isn't evaluated yet. Later in the code, we'll assign the image G as the model input, so that\n",
    "# when we run the session, this will be the activations drawn from the appropriate layer, with G as input.\n",
    "a_G = out\n",
    "\n",
    "# Compute the content cost\n",
    "J_content = compute_content_cost(a_C, a_G)\n",
    "\n",
    "# Assign the input of the model to be the \"style\" image\n",
    "sess.run(model['input'].assign(style_image))\n",
    "\n",
    "# Compute the style cost\n",
    "J_style = compute_style_cost(model, STYLE_LAYERS)\n",
    "\n",
    "J = total_cost(J_content, J_style, alpha=10, beta=40)\n",
    "\n",
    "# define optimizer (1 line)\n",
    "optimizer = tf.train.AdamOptimizer(2.0)\n",
    "\n",
    "# define train_step (1 line)\n",
    "train_step = optimizer.minimize(J)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}